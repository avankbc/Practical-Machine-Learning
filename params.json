{"name":"Practical-machine-learning","tagline":"coursera","body":"\r\n<body>\r\n\r\n<div class=\"container-fluid main-container\">\r\n<div id=\"header\">\r\n<h1 class=\"title\">Predicting Human Activity</h1>\r\n<h4 class=\"author\"><em>Avan Koh</em></h4>\r\n<h4 class=\"date\"><em>Sunday, Jan 25, 2015</em></h4>\r\n</div>\r\n\r\n<p><br></p>\r\n<div id=\"executive-summary\" class=\"section level2\">\r\n<h2>Executive Summary</h2>\r\n<p>This detailed analysis has been performed to fulfill the requirements of the course project for the course <a href=\"https://www.coursera.org/course/predmachlearn\" title=\"Regression Models\">Practical Machine Learning</a> offered by the <a href=\"https://www.coursera.org/jhu\" title=\"Johns Hopkins University\">Johns Hopkins University</a> on <a href=\"https://www.coursera.org/\" title=\"Coursera\">Coursera</a>. Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.</p>\r\n<p>Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.</p>\r\n<p>Read more about the data set details in the <a href=\"http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises#ixzz35JVTyesz\" title=\"Groupware@LES\"><a href=\"mailto:Groupware@LES\">Groupware@LES</a></a> website.</p>\r\n<p>The main objectives of this project are as follows</p>\r\n<ul>\r\n<li>Predict the manner in which they did the exercise depicted by the <code>classe</code> variable.</li>\r\n<li>Build a prediction model using different features and cross-validation technique.</li>\r\n<li>Calculate the out of sample error.</li>\r\n<li>Use the prediction model to predict <code>20</code> different test cases provided. <br></li>\r\n</ul>\r\n</div>\r\n<div id=\"loading-the-data\" class=\"section level4\">\r\n<h4><u>Loading the data</u></h4>\r\n<p>Next, we read the file using appropriate functions and load in the data using the following commands. We just check if the data is loaded correctly by viewing a few rows and columns of the data frame.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">training &lt;-<span class=\"st\"> </span><span class=\"kw\">read.csv</span>(<span class=\"st\">&quot;pml-training.csv&quot;</span>,<span class=\"dt\">na.strings=</span><span class=\"kw\">c</span>(<span class=\"st\">&quot;NA&quot;</span>,<span class=\"st\">&quot;&quot;</span>))\r\ntesting &lt;-<span class=\"kw\">read.csv</span>(<span class=\"st\">&quot;pml-testing.csv&quot;</span>,<span class=\"dt\">na.strings=</span><span class=\"kw\">c</span>(<span class=\"st\">&quot;NA&quot;</span>,<span class=\"st\">&quot;&quot;</span>))\r\n<span class=\"kw\">dim</span>(training)</code></pre>\r\n<pre><code>## [1] 19622   160</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class=\"kw\">dim</span>(testing)</code></pre>\r\n<pre><code>## [1]  20 160</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">training[<span class=\"dv\">1</span>:<span class=\"dv\">5</span>,<span class=\"kw\">c</span>(<span class=\"st\">'user_name'</span>,<span class=\"st\">'classe'</span>,<span class=\"st\">'num_window'</span>,<span class=\"st\">'roll_belt'</span>,<span class=\"st\">'pitch_belt'</span>)]</code></pre>\r\n<pre><code>##   user_name classe num_window roll_belt pitch_belt\r\n## 1  carlitos      A         11      1.41       8.07\r\n## 2  carlitos      A         11      1.41       8.07\r\n## 3  carlitos      A         11      1.42       8.07\r\n## 4  carlitos      A         12      1.48       8.05\r\n## 5  carlitos      A         12      1.48       8.07</code></pre>\r\n<p><br></p>\r\n</div>\r\n<div id=\"processing-the-data\" class=\"section level4\">\r\n<h4><u>Processing the data</u></h4>\r\n<p>First, we check how many columns have <code>NA</code> values in the training and testing data and what is the quantity of <code>NA</code> values present.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class=\"kw\">sum</span>(<span class=\"kw\">is.na</span>(training))  <span class=\"co\"># Total NA values</span></code></pre>\r\n<pre><code>[1] 1921600</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">t1 &lt;-<span class=\"st\"> </span><span class=\"kw\">table</span>(<span class=\"kw\">colSums</span>(<span class=\"kw\">is.na</span>(training)))\r\nt2 &lt;-<span class=\"st\"> </span><span class=\"kw\">table</span>(<span class=\"kw\">colSums</span>(<span class=\"kw\">is.na</span>(testing)))\r\n<span class=\"kw\">pandoc.table</span>(t1, <span class=\"dt\">style =</span> <span class=\"st\">&quot;grid&quot;</span>, <span class=\"dt\">justify =</span> <span class=\"st\">'left'</span>, <span class=\"dt\">caption =</span> <span class=\"st\">'Training data column NA frequencies'</span>)</code></pre>\r\n<pre><code>\r\n\r\n+----+-----+\r\n| 60 | 100 |\r\n+----+-----+\r\n\r\nTable: Training data column NA frequencies</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class=\"kw\">pandoc.table</span>(t2, <span class=\"dt\">style =</span> <span class=\"st\">&quot;grid&quot;</span>, <span class=\"dt\">justify =</span> <span class=\"st\">'left'</span>, <span class=\"dt\">caption =</span> <span class=\"st\">'Testing data column NA frequencies'</span>)</code></pre>\r\n<pre><code>\r\n\r\n+----+-----+\r\n| 60 | 100 |\r\n+----+-----+\r\n\r\nTable: Testing data column NA frequencies</code></pre>\r\n<p>Looking at the above values it is clear that <code>60</code> variables have <code>0</code> NA values while the rest have <code>NA</code> values for almost all the rows of the dataset, so we are going to ignore them using the following code segment.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class=\"co\"># for training dataset</span>\r\ncolumnNACounts &lt;-<span class=\"st\"> </span><span class=\"kw\">colSums</span>(<span class=\"kw\">is.na</span>(training))        <span class=\"co\"># getting NA counts for all columns</span>\r\nbadColumns &lt;-<span class=\"st\"> </span>columnNACounts &gt;=<span class=\"st\"> </span><span class=\"dv\">19000</span>             <span class=\"co\"># ignoring columns with majority NA values</span>\r\ncleanTrainingdata &lt;-<span class=\"st\"> </span>training[!badColumns]        <span class=\"co\"># getting clean data</span>\r\n<span class=\"kw\">sum</span>(<span class=\"kw\">is.na</span>(cleanTrainingdata))                     <span class=\"co\"># checking for NA values</span></code></pre>\r\n<pre><code>## [1] 0</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">cleanTrainingdata &lt;-<span class=\"st\"> </span>cleanTrainingdata[, <span class=\"kw\">c</span>(<span class=\"dv\">7</span>:<span class=\"dv\">60</span>)] <span class=\"co\"># removing unnecessary columns</span>\r\n\r\n<span class=\"co\"># for testing dataset</span>\r\ncolumnNACounts &lt;-<span class=\"st\"> </span><span class=\"kw\">colSums</span>(<span class=\"kw\">is.na</span>(testing))         <span class=\"co\"># getting NA counts for all columns</span>\r\nbadColumns &lt;-<span class=\"st\"> </span>columnNACounts &gt;=<span class=\"st\"> </span><span class=\"dv\">20</span>                <span class=\"co\"># ignoring columns with majority NA values</span>\r\ncleanTestingdata &lt;-<span class=\"st\"> </span>testing[!badColumns]        <span class=\"co\"># getting clean data</span>\r\n<span class=\"kw\">sum</span>(<span class=\"kw\">is.na</span>(cleanTestingdata))                     <span class=\"co\"># checking for NA values</span></code></pre>\r\n<pre><code>## [1] 0</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">cleanTestingdata &lt;-<span class=\"st\"> </span>cleanTestingdata[, <span class=\"kw\">c</span>(<span class=\"dv\">7</span>:<span class=\"dv\">60</span>)] <span class=\"co\"># removing unnecessary columns</span></code></pre>\r\n<p>Now since we donâ€™t have any NA values we are ready to do some exploratory analysis and build our prediction model. <br></p>\r\n</div>\r\n</div>\r\n<div id=\"exploratory-data-analysis\" class=\"section level2\">\r\n<h2>Exploratory Data Analysis</h2>\r\n<p>We look at some summary statistics and frequency plot for the <code>classe</code> variable.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">s &lt;-<span class=\"st\"> </span><span class=\"kw\">summary</span>(cleanTrainingdata$classe)\r\n<span class=\"kw\">pandoc.table</span>(s, <span class=\"dt\">style =</span> <span class=\"st\">&quot;grid&quot;</span>, <span class=\"dt\">justify =</span> <span class=\"st\">'left'</span>, <span class=\"dt\">caption =</span> <span class=\"st\">'`classe` frequencies'</span>)</code></pre>\r\n<pre><code>\r\n\r\n+------+------+------+------+------+\r\n| 5580 | 3797 | 3422 | 3216 | 3607 |\r\n+------+------+------+------+------+\r\n\r\nTable: `classe` frequencies</code></pre>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class=\"kw\">plot</span>(cleanTrainingdata$classe,<span class=\"dt\">col=</span><span class=\"kw\">rainbow</span>(<span class=\"dv\">5</span>),<span class=\"dt\">main =</span> <span class=\"st\">&quot;`classe` frequency plot&quot;</span>)</code></pre>\r\n<p><img src=\"data:image/png;base64,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\" title alt width=\"672\" /> <br></p>\r\n</div>\r\n<div id=\"model-building\" class=\"section level2\">\r\n<h2>Model building</h2>\r\n<p>In this section, we will build a machine learning model for predicting the <code>classe</code> value based on the other features of the dataset. <br></p>\r\n<div id=\"data-partitioning\" class=\"section level4\">\r\n<h4><u>Data partitioning</u></h4>\r\n<p>First we partition the <code>cleanTrainingdata</code> dataset into training and testing data sets for building our model using the following code segment.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">partition &lt;-<span class=\"st\"> </span><span class=\"kw\">createDataPartition</span>(<span class=\"dt\">y =</span> cleanTrainingdata$classe, <span class=\"dt\">p =</span> <span class=\"fl\">0.6</span>, <span class=\"dt\">list =</span> <span class=\"ot\">FALSE</span>)\r\ntrainingdata &lt;-<span class=\"st\"> </span>cleanTrainingdata[partition, ]\r\ntestdata &lt;-<span class=\"st\"> </span>cleanTrainingdata[-partition, ]</code></pre>\r\n<p><br></p>\r\n</div>\r\n<div id=\"model-building-1\" class=\"section level4\">\r\n<h4><u>Model building</u></h4>\r\n<p>Now, using the features in the <code>trainingdata</code> dataset, we will build our model using the <code>Random Forest</code> machine learning technique.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\"><span class=\"co\">#trainInds &lt;- sample(nrow(cleanTrainingdata), 3000)</span>\r\n<span class=\"co\">#trainingdata&lt;-cleanTrainingdata[trainInds,]</span>\r\nmodel &lt;-<span class=\"st\"> </span><span class=\"kw\">train</span>(classe ~<span class=\"st\"> </span>., <span class=\"dt\">data =</span> trainingdata, <span class=\"dt\">method =</span> <span class=\"st\">&quot;rf&quot;</span>, <span class=\"dt\">prox =</span> <span class=\"ot\">TRUE</span>, <span class=\"dt\">trControl =</span> <span class=\"kw\">trainControl</span>(<span class=\"dt\">method =</span> <span class=\"st\">&quot;cv&quot;</span>, <span class=\"dt\">number =</span> <span class=\"dv\">4</span>, <span class=\"dt\">allowParallel =</span> <span class=\"ot\">TRUE</span>))\r\nmodel</code></pre>\r\n<pre><code>## Random Forest \r\n## \r\n## 11776 samples\r\n##    53 predictor\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (4 fold) \r\n## \r\n## Summary of sample sizes: 8833, 8831, 8832, 8832 \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   \r\n##    2    0.9915924  0.9893629  0.004248675  0.005377877\r\n##   27    0.9965182  0.9955954  0.001626636  0.002058587\r\n##   53    0.9943104  0.9928026  0.001221020  0.001545453\r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 27.</code></pre>\r\n<p>We build the model using <code>4-fold</code> cross validation. <br></p>\r\n</div>\r\n<div id=\"in-sample-accuracy\" class=\"section level4\">\r\n<h4><u>In sample accuracy</u></h4>\r\n<p>Here, we calculate the <code>in sample</code> accuracy which is the prediction accuracy of our model on the training data set.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">training_pred &lt;-<span class=\"st\"> </span><span class=\"kw\">predict</span>(model, trainingdata)\r\n<span class=\"kw\">confusionMatrix</span>(training_pred, trainingdata$classe)</code></pre>\r\n<pre><code>## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 3348    0    0    0    0\r\n##          B    0 2279    0    0    0\r\n##          C    0    0 2054    0    0\r\n##          D    0    0    0 1930    0\r\n##          E    0    0    0    0 2165\r\n## \r\n## Overall Statistics\r\n##                                      \r\n##                Accuracy : 1          \r\n##                  95% CI : (0.9997, 1)\r\n##     No Information Rate : 0.2843     \r\n##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  \r\n##                                      \r\n##                   Kappa : 1          \r\n##  Mcnemar's Test P-Value : NA         \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838\r\n## Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838\r\n## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000</code></pre>\r\n<p>Thus from the above statistics we see that the <code>in sample</code> accuracy value is <code>1</code> which is <code>100%</code>. <br></p>\r\n</div>\r\n<div id=\"out-of-sample-accuracy\" class=\"section level4\">\r\n<h4><u>Out of sample accuracy</u></h4>\r\n<p>Here, we calculate the <code>out of sample</code> accuracy which is the prediction accuracy of our model on the testing data set.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">testing_pred &lt;-<span class=\"st\"> </span><span class=\"kw\">predict</span>(model, testdata)\r\n<span class=\"kw\">confusionMatrix</span>(testing_pred, testdata$classe)</code></pre>\r\n<pre><code>## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 2231    2    0    0    0\r\n##          B    0 1514    5    0    3\r\n##          C    0    2 1363    5    0\r\n##          D    0    0    0 1281    4\r\n##          E    1    0    0    0 1435\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9972          \r\n##                  95% CI : (0.9958, 0.9982)\r\n##     No Information Rate : 0.2845          \r\n##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9965          \r\n##  Mcnemar's Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9996   0.9974   0.9963   0.9961   0.9951\r\n## Specificity            0.9996   0.9987   0.9989   0.9994   0.9998\r\n## Pos Pred Value         0.9991   0.9947   0.9949   0.9969   0.9993\r\n## Neg Pred Value         0.9998   0.9994   0.9992   0.9992   0.9989\r\n## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2843   0.1930   0.1737   0.1633   0.1829\r\n## Detection Prevalence   0.2846   0.1940   0.1746   0.1638   0.1830\r\n## Balanced Accuracy      0.9996   0.9981   0.9976   0.9978   0.9975</code></pre>\r\n<p>Thus from the above statistics we see that the <code>out of sample</code> accuracy value is <code>0.998</code> which is <code>99.8%</code>.</p>\r\n<p><br></p>\r\n</div>\r\n</div>\r\n<div id=\"prediction-assignment\" class=\"section level2\">\r\n<h2>Prediction Assignment</h2>\r\n<p>Here, we apply the machine learning algorithm we built above, to each of the 20 test cases in the testing data set provided.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">answers &lt;-<span class=\"st\"> </span><span class=\"kw\">predict</span>(model, cleanTestingdata)\r\nanswers &lt;-<span class=\"st\"> </span><span class=\"kw\">as.character</span>(answers)\r\nanswers</code></pre>\r\n<pre><code>##  [1] &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;E&quot; &quot;D&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot; &quot;E&quot; &quot;E&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot;</code></pre>\r\n<p>Finally, we write the answers to files as specified by the course instructor using the following code segment.</p>\r\n<pre class=\"sourceCode r\"><code class=\"sourceCode r\">pml_write_files =<span class=\"st\"> </span>function(x) {\r\n    n =<span class=\"st\"> </span><span class=\"kw\">length</span>(x)\r\n    for (i in <span class=\"dv\">1</span>:n) {\r\n        filename =<span class=\"st\"> </span><span class=\"kw\">paste0</span>(<span class=\"st\">&quot;problem_id_&quot;</span>, i, <span class=\"st\">&quot;.txt&quot;</span>)\r\n        <span class=\"kw\">write.table</span>(x[i], <span class=\"dt\">file =</span> filename, <span class=\"dt\">quote =</span> <span class=\"ot\">FALSE</span>, <span class=\"dt\">row.names =</span> <span class=\"ot\">FALSE</span>, \r\n            <span class=\"dt\">col.names =</span> <span class=\"ot\">FALSE</span>)\r\n    }\r\n}\r\n\r\n<span class=\"kw\">pml_write_files</span>(answers)</code></pre>\r\n<p>On submission, we would see that all the predicted values are correct and a score of <code>20\\20</code> is obtained. <br></p>\r\n</div>\r\n<div id=\"conclusion\" class=\"section level2\">\r\n<h2>Conclusion</h2>\r\n<p>We choose <code>Random Forest</code> as our machine learning algorithm for building our model because,</p>\r\n<ul>\r\n<li>Builds a highly accurate classifier.</li>\r\n<li>Can handle thousands of variables.</li>\r\n<li>Balances bias and variance trade-offs by settling for a balanced model.</li>\r\n<li>Using <code>k-fold</code> cross validation builds a robust model.</li>\r\n</ul>\r\n<p>We also obtained a really good accuracy based on the statistics we obtained above.</p>\r\n</div>\r\n\r\n\r\n</div>\r\n\r\n<script>\r\n\r\n// add bootstrap table styles to pandoc tables\r\n$(document).ready(function () {\r\n  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');\r\n});\r\n\r\n</script>\r\n\r\n<!-- dynamically load mathjax for compatibility with self-contained -->\r\n<script>\r\n  (function () {\r\n    var script = document.createElement(\"script\");\r\n    script.type = \"text/javascript\";\r\n    script.src  = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\r\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\r\n  })();\r\n</script>\r\n\r\n</body>\r\n</html>\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}